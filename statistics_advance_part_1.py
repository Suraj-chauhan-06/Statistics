# -*- coding: utf-8 -*-
"""Statistics Advance Part 1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fWVYLxH2b4wdrmfSqPpOD3srAJNihdiT

1. What is a random variable in probability theory?
A random variable is a numerical outcome of a random process or experiment. It assigns a real number to each outcome in the sample space.


2. Types of Random Variables
Discrete: Takes countable values (e.g., number of heads in 3 coin tosses).

Continuous: Takes an infinite number of values in an interval (e.g., height, temperature).


3. Difference Between Discrete and Continuous Distributions
Discrete: Probability is assigned to specific values.

Continuous: Probability is assigned over intervals; individual points have zero probability.

4. Probability Distribution Function (PDF)
For continuous variables, PDF describes the likelihood of a variable falling within a range. It’s the derivative of the CDF.



5. Difference Between CDF and PDF
PDF gives the density at a point.

CDF gives the probability that the variable is less than or equal to a value.


6. Discrete Uniform Distribution
Each outcome in a set of n equally likely outcomes has the same probability, i.e., 1/n.



7. Key Properties of Bernoulli Distribution
Only two outcomes: success (1) and failure (0)

Mean = p, Variance = p(1 - p)



8. Binomial Distribution
Models the number of successes in a fixed number of independent Bernoulli trials. Used in quality testing, surveys, etc.


9. Poisson Distribution and Applications
Describes the number of events in a fixed interval. Used in traffic flow, call centers, etc.



10. Continuous Uniform Distribution
Each value in an interval [a, b] has equal probability. PDF = 1 / (b - a)



11. Characteristics of a Normal Distribution
Bell-shaped curve

Symmetrical around mean

Mean = Median = Mode



12. Standard Normal Distribution
A normal distribution with mean = 0 and standard deviation = 1. Used to compute probabilities and Z-scores.



13. Central Limit Theorem (CLT)
It states that the sampling distribution of the mean of a large number of independent, identically distributed variables tends to be normal.


14. CLT & Normal Distribution
The CLT explains why many statistics are approximately normally distributed, even if the underlying data isn't.


15. Application of Z-statistics in Hypothesis Testing
Used to determine whether to reject a null hypothesis by comparing a sample mean to a population mean.


16. How to Calculate Z-score
𝑍
=
𝑓
𝑟
𝑎
𝑐
(
𝑋
−
𝜇
)
𝜎
Z=
frac(X−μ)σ
Represents how many standard deviations a value X is from the mean.


17. Point & Interval Estimates
Point: Single value estimate (e.g., sample mean).

Interval: Range of values (e.g., 95% confidence interval) likely to contain the parameter.


18. Confidence Intervals
They indicate the range in which a population parameter lies, with a certain level of confidence (e.g., 95%).



19. Relationship Between Z-score & Confidence Interval
Z-scores are used to determine the margin of error for confidence intervals.


20. Z-scores to Compare Distributions
Helps compare values from different distributions by standardizing them.



21. Assumptions of CLT
Sample size should be large (n > 30 is common rule)

Independent observations

Identically distributed variables


22. Expected Value
The average or mean value expected from a probability distribution.



23. Probability Distribution & Expected Outcome
Expected value is the weighted average of all possible outcomes using their probabilities.

Python Programs – Statistics Advanced Assignment
"""

#1. Generate a Random Variable

import random

random_variable = random.randint(1, 100)
print("Random Variable:", random_variable)

#2. Discrete Uniform Distribution – PMF


import matplotlib.pyplot as plt
import numpy as np

values = np.arange(1, 7)
probabilities = np.full_like(values, 1/len(values), dtype=float)

plt.bar(values, probabilities)
plt.title("PMF of Discrete Uniform Distribution (1 to 6)")
plt.xlabel("Value")
plt.ylabel("Probability")
plt.show()

#3. Bernoulli Distribution – PDF

def bernoulli_pdf(x, p):
    return p if x == 1 else (1 - p)

print("P(X=1):", bernoulli_pdf(1, 0.7))
print("P(X=0):", bernoulli_pdf(0, 0.7))

#4. Binomial Distribution – Simulation & Histogram

from scipy.stats import binom

n, p = 10, 0.5
data = binom.rvs(n=n, p=p, size=1000)

plt.hist(data, bins=range(n+2), edgecolor='black', density=True)
plt.title("Binomial Distribution (n=10, p=0.5)")
plt.xlabel("Successes")
plt.ylabel("Frequency")
plt.show()

#5. Poisson Distribution – Visualization

from scipy.stats import poisson

mu = 3
x = np.arange(0, 10)
pmf = poisson.pmf(x, mu)

plt.bar(x, pmf)
plt.title("Poisson Distribution (mu = 3)")
plt.xlabel("X")
plt.ylabel("PMF")
plt.show()

#6. CDF of Discrete Uniform Distribution

cdf = np.cumsum(probabilities)
plt.step(values, cdf)
plt.title("CDF of Discrete Uniform Distribution")
plt.xlabel("Value")
plt.ylabel("Cumulative Probability")
plt.grid(True)
plt.show()

#7. Continuous Uniform Distribution – Visualization

from scipy.stats import uniform

data = uniform.rvs(loc=0, scale=1, size=1000)
plt.hist(data, bins=30, edgecolor='black', density=True)
plt.title("Continuous Uniform Distribution")
plt.show()

#8. Normal Distribution – Simulation

mean, std_dev = 0, 1
normal_data = np.random.normal(mean, std_dev, 1000)

plt.hist(normal_data, bins=30, edgecolor='black', density=True)
plt.title("Normal Distribution Histogram")
plt.show()

#9. Z-scores – Calculation & Plot

from scipy.stats import zscore

z_scores = zscore(normal_data)
plt.hist(z_scores, bins=30, edgecolor='black')
plt.title("Z-score Distribution")
plt.show()

#10. Central Limit Theorem Simulation

samples = [np.mean(np.random.exponential(scale=2, size=30)) for _ in range(1000)]

plt.hist(samples, bins=30, edgecolor='black')
plt.title("CLT Simulation Using Exponential Distribution")
plt.xlabel("Sample Mean")
plt.ylabel("Frequency")
plt.show()

#11 Simulate multiple samples from a normal distribution and verify the Central Limit Theorem


import numpy as np
import matplotlib.pyplot as plt

sample_means = [np.mean(np.random.normal(loc=50, scale=10, size=30)) for _ in range(1000)]
plt.hist(sample_means, bins=30, edgecolor='black')
plt.title("CLT with Normal Distribution")
plt.xlabel("Sample Means")
plt.ylabel("Frequency")
plt.show()

#12. Standard Normal Distribution (mean = 0, std = 1)

x = np.linspace(-4, 4, 1000)
pdf = (1 / np.sqrt(2 * np.pi)) * np.exp(-x**2 / 2)

plt.plot(x, pdf)
plt.title("Standard Normal Distribution")
plt.xlabel("Z")
plt.ylabel("PDF")
plt.grid(True)
plt.show()

#13. Generate random variables using binomial distribution

binom_data = np.random.binomial(n=10, p=0.5, size=1000)
plt.hist(binom_data, bins=11, edgecolor='black')
plt.title("Binomial Distribution (n=10, p=0.5)")
plt.show()

#14. Z-score for a data point

value = 85
mean = 70
std = 10
z = (value - mean) / std
print("Z-score:", z)

#15. Hypothesis testing using Z-statistics

from scipy.stats import norm

# Sample
sample_mean = 73
population_mean = 70
std_dev = 10
n = 30

z = (sample_mean - population_mean) / (std_dev / np.sqrt(n))
p_value = 1 - norm.cdf(z)

print("Z-statistic:", z)
print("P-value:", p_value)

#16. Create a confidence interval for a dataset


data = np.random.normal(100, 15, 100)
mean = np.mean(data)
std = np.std(data)
confidence = 0.95

z_critical = norm.ppf(1 - (1 - confidence) / 2)
margin_error = z_critical * (std / np.sqrt(len(data)))

ci = (mean - margin_error, mean + margin_error)
print("95% Confidence Interval:", ci)

#17. Confidence interval for mean from normal data

normal_data = np.random.normal(50, 5, 100)
mean = np.mean(normal_data)
std = np.std(normal_data)

z_crit = norm.ppf(0.975)
margin_error = z_crit * (std / np.sqrt(100))

print("Confidence Interval:", (mean - margin_error, mean + margin_error))

#18. PDF of a normal distribution

from scipy.stats import norm

x = np.linspace(-4, 4, 1000)
pdf = norm.pdf(x, loc=0, scale=1)

plt.plot(x, pdf)
plt.title("PDF of Normal Distribution")
plt.grid(True)
plt.show()

#19. CDF of a Poisson distribution


from scipy.stats import poisson

x = np.arange(0, 10)
cdf = poisson.cdf(x, mu=3)

plt.step(x, cdf, where='post')
plt.title("CDF of Poisson Distribution")
plt.grid(True)
plt.show()

#20. Simulate a continuous uniform distribution and expected value


data = np.random.uniform(low=0, high=10, size=1000)
expected_value = np.mean(data)
print("Expected Value:", expected_value)

#21. Compare standard deviations of two datasets

data1 = np.random.normal(50, 5, 100)
data2 = np.random.normal(50, 10, 100)

std1 = np.std(data1)
std2 = np.std(data2)

plt.hist(data1, bins=20, alpha=0.5, label='std=5')
plt.hist(data2, bins=20, alpha=0.5, label='std=10')
plt.legend()
plt.title("Comparison of Standard Deviations")
plt.show()

print("Standard Deviations -> Dataset1:", std1, "| Dataset2:", std2)

#22. Range and Interquartile Range (IQR)

data = np.random.normal(60, 10, 1000)
range_val = np.ptp(data)
iqr_val = np.percentile(data, 75) - np.percentile(data, 25)

print("Range:", range_val)
print("IQR:", iqr_val)

#23. Z-score normalization and visualization

from sklearn.preprocessing import StandardScaler

data = np.random.normal(100, 15, 100)
scaler = StandardScaler()
z_normalized = scaler.fit_transform(data.reshape(-1, 1))

plt.hist(z_normalized, bins=30, edgecolor='black')
plt.title("Z-score Normalized Data")
plt.show()

#24. Skewness and Kurtosis

from scipy.stats import skew, kurtosis

data = np.random.normal(0, 1, 1000)

print("Skewness:", skew(data))
print("Kurtosis:", kurtosis(data))  # Normal dist kurtosis ≈ 0

#25.